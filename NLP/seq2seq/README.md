# Seq2Seq(Sequence to Sequence Learning with Neural Networks)
> Paper : [Sequence to Sequence Learning with Neural Networks](https://arxiv.org/pdf/1409.3215)

## 1. Introduction

## 2. The model

## 3. Experiment

### 3.1. Dataset details

### 3.2. Decoding and Rescoring

### 3.3. Reversing the Source Sentences

### 3.4. Training details

### 3.5. Parallelization

### 3.6. Experimental Results

### 3.7. Performance on long sentences



### 후기  
**느낀점**     

**아쉬운점**  

**배운점**  
- 논문의 주요 구조(abstract, introduction, experiment 등)에 대해 구조화하면서 읽는 것에 대한 필요성을 느꼈다.  

<details>
<summary>Abstract 구조화</summary>

#### 1. 연구 목표 (What & Why)
- 이 논문은 어떤 문제를 해결하려고 하는가?
- 기존 연구의 한계는 무엇인가?
- 연구의 핵심 기여(contribution)는 무엇인가?

#### 2. 제안된 방법 (How)
- 어떤 접근법을 사용했는가?
- 모델의 구조나 방법론의 특징은 무엇인가?

#### 3. 실험 및 결과 (Does it work?)
- 연구에서 수행한 실험은 무엇인가?
- 제안된 방법의 성능은 어떠한가?
- 어떤 평가 지표를 사용했으며, 기존 방법과 비교했을 때 얼마나 성능이 향상되었는가?

#### 4. 비교 및 의의 (Comparison & Contribution)
- 기존 방법과 비교했을 때 어떤 점이 개선되었는가?
- 연구 결과가 어떤 의미를 가지는가?

#### 5. 흥미로운 추가 발견 (Interesting Insights)
- 연구 과정에서 발견한 흥미로운 점은 있는가?
- 연구자가 강조하는 추가적인 통찰(insight)이 있는가?

</details>


